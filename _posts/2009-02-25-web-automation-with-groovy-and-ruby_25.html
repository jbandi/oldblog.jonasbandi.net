---
layout: post
title: Web automation with Groovy and Ruby
date: '2009-02-25T21:13:00.001+01:00'
author: Jonas Bandi
tags:
- groovy
- programming
- ruby/rails
- javablog
modified_time: '2009-02-25T21:21:11.873+01:00'
blogger_id: tag:blogger.com,1999:blog-5763764290649132593.post-6585960965783478333
blogger_orig_url: http://blog.jonasbandi.net/2009/02/web-automation-with-groovy-and-ruby_25.html
---

For a small private project I need to do some web automation.
<br/> 
<br/>
I wanted to use a scripting language and decided to give <a href="http://www.ruby-lang.org/en/">Ruby</a> and <a href="http://groovy.codehaus.org/">Groovy</a> a try.
<br/>
<br/>
In Ruby there is the <a href="http://mechanize.rubyforge.org/mechanize/">Mechanize library</a>. In Groovy there are <a href="http://groovy.codehaus.org/Testing+Web+Applications">different options</a>.
<br/>
<br/>
The Ruby Mechanize library seems very intuitive:
</em>
<div style="border:solid 1px silver;width:400px;overflow:auto">
<div style="width:1100px;"> 
<pre name="code" class="ruby">
  require 'rubygems'
  require 'mechanize'

  a = WWW::Mechanize.new { |agent|
    agent.user_agent_alias = 'Mac Safari'
  }

  a.get('http://google.com/') do |page|
    search_result = page.form_with(:name => 'f') do |search|
      search.q = 'Hello world'
    end.submit

    search_result.links.each do |link|
      puts link.text
    end
  end

</pre>
</div>
</div>
<br/>
I like the DSLish way to both, <a href="http://en.wikipedia.org/wiki/Web_scraping">scrape</a> (eg: <code style="border: solid 1px silver; background-color:LightGray">earch_result.links.each</code>) and manipulate (eg: <code style="border: solid 1px silver; background-color:LightGray">search.q = 'Hello world'</code>) a web page.
<br/>
<br/>
In Groovy <a href="http://en.wikipedia.org/wiki/Web_scraping">scraping</a> is also pretty DSLish:
<div style="border:solid 1px silver;width:400px;overflow:auto">
<div style="width:1100px;"> 
<pre name="code" class="java">
def page = new XmlSlurper(new org.cyberneko.html.parsers.SAXParser()).parse('http://groovy.codehaus.org/')
def data = page.depthFirst().grep{ it.name() == 'A' && it.@href.toString().endsWith('.html') }.'@href'
data.each { println it }
</pre>
</div>
</div>
But it makes a bit a less concise impression than the Ruby version.
<br/>
<br/>
Manipulating a web page with groovy unfortunately is clumsier:
<div style="border:solid 1px silver;width:400px;overflow:auto">
<div style="width:1100px;"> 
<pre name="code" class="java">
import com.gargoylesoftware.htmlunit.WebClient

def webClient = new WebClient()
def page = webClient.getPage('http://www.google.com')
// check page title
assert 'Google' == page.titleText
// fill in form and submit it
def form = page.getFormByName('f')
def field = form.getInputByName('q')
field.setValueAttribute('Groovy')
def button = form.getInputByName('btnG')
def result = button.click()
// check groovy home page appears in list (assumes it's on page 1)
assert result.anchors.any{ a -> a.hrefAttribute == 'http://groovy.codehaus.org/' }

</pre>
</div>
</div>
This is less DSLish and much more old-scool imperative... the different styles for scraping and manipulating is a bit unfortunate (however you can also use HtmlUnit for scraping).
<br/>
<br/>
<div style="align:right; font-size: 10px; clear:right; ">
<br/>
<p><a  href="http://twitter.com/jbandi"><img style="margin: 0px 0px 0px 0px" src="http://www.google.com/s2/favicons?domain=twitter.com" alt="http://www.google.com/s2/favicons?domain=twitter.com" border="0" align="left" height="13px"/> follow me on twitter, I need some friends :-)</a></p></div>
